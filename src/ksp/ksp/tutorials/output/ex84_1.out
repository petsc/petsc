Mat Object: 2 MPI processes
  type: mpiaij
  row 0:   (0, 2.)    (1, -1.)   
  row 1:   (1, 3.)    (2, -1.)   
  row 2:   (2, 4.)    (3, -1.)   
  row 3:   (3, 5.)    (4, -1.)   
  row 4:   (4, 6.)    (5, -1.)   
  row 5:   (4, -0.5)    (5, 7.)   
IS Object: 2 MPI processes
  type: stride
[0] Number of indices in (stride) set 1
[0] 0 0
[1] Number of indices in (stride) set 2
[1] 0 2
[1] 1 4
IS Object: 2 MPI processes
  type: stride
[0] Number of indices in (stride) set 1
[0] 0 1
[1] Number of indices in (stride) set 2
[1] 0 3
[1] 1 5
IS Object: 2 MPI processes
  type: general
[0] Number of indices in set 1
[0] 0 0
[1] Number of indices in set 1
[1] 0 3
Mat Object: 2 MPI processes
  type: mpiaij
  row 0:   (0, 1.)    (1, 0.)   
  row 1:   (1, 3.)    (2, -1.)   
  row 2:   (2, 4.)    (3, 0.)   
  row 3:   (3, 1.)    (4, 0.)   
  row 4:   (4, 6.)    (5, -1.)   
  row 5:   (4, -0.5)    (5, 7.)   
  0 KSP Residual norm 2.449489742783e+00
    Residual norms for redistribute_ solve.
    0 KSP Residual norm 4.747000485090e-01
    1 KSP Residual norm 2.445422843562e-02
    2 KSP Residual norm 2.021518719930e-17
  1 KSP Residual norm 3.330669073875e-16
KSP Object: 2 MPI processes
  type: preonly
  maximum iterations=10000, initial guess is zero
  tolerances: relative=1e-05, absolute=1e-50, divergence=10000.
  left preconditioning
  using NONE norm type for convergence test
PC Object: 2 MPI processes
  type: redistribute
      Number rows eliminated 3 Percentage rows eliminated 50.
    Redistribute preconditioner: 
  KSP Object: (redistribute_) 2 MPI processes
    type: gmres
      restart=30, using Classical (unmodified) Gram-Schmidt Orthogonalization with no iterative refinement
      happy breakdown tolerance 1e-30
    maximum iterations=10000, initial guess is zero
    tolerances: relative=1e-05, absolute=1e-50, divergence=10000.
    left preconditioning
    using PRECONDITIONED norm type for convergence test
  PC Object: (redistribute_) 2 MPI processes
    type: fieldsplit
      FieldSplit with MULTIPLICATIVE composition: total splits = 2
      Solver info for each split is in the following KSP objects:
    Split number 0 Defined by IS
    KSP Object: (redistribute_fieldsplit_0_) 2 MPI processes
      type: preonly
      maximum iterations=10000, initial guess is zero
      tolerances: relative=1e-05, absolute=1e-50, divergence=10000.
      left preconditioning
      using NONE norm type for convergence test
    PC Object: (redistribute_fieldsplit_0_) 2 MPI processes
      type: bjacobi
        number of blocks = 2
        Local solver information for first block is in the following KSP and PC objects on rank 0:
        Use -redistribute_fieldsplit_0_ksp_view ::ascii_info_detail to display information for all blocks
        KSP Object: (redistribute_fieldsplit_0_sub_) 1 MPI process
          type: preonly
          maximum iterations=10000, initial guess is zero
          tolerances: relative=1e-05, absolute=1e-50, divergence=10000.
          left preconditioning
          using NONE norm type for convergence test
        PC Object: (redistribute_fieldsplit_0_sub_) 1 MPI process
          type: ilu
            out-of-place factorization
            0 levels of fill
            tolerance for zero pivot 2.22045e-14
            matrix ordering: natural
            factor fill ratio given 1., needed 1.
              Factored matrix follows:
                Mat Object: (redistribute_fieldsplit_0_sub_) 1 MPI process
                  type: seqaij
                  rows=1, cols=1
                  package used to perform factorization: petsc
                  total: nonzeros=1, allocated nonzeros=1
                    not using I-node routines
          linear system matrix = precond matrix:
          Mat Object: (redistribute_fieldsplit_0_sub_) 1 MPI process
            type: seqaij
            rows=1, cols=1
            total: nonzeros=1, allocated nonzeros=1
            total number of mallocs used during MatSetValues calls=0
              not using I-node routines
      linear system matrix = precond matrix:
      Mat Object: (redistribute_fieldsplit_0_) 2 MPI processes
        type: mpiaij
        rows=1, cols=1
        total: nonzeros=1, allocated nonzeros=1
        total number of mallocs used during MatSetValues calls=0
          not using I-node (on process 0) routines
    Split number 1 Defined by IS
    KSP Object: (redistribute_fieldsplit_1_) 2 MPI processes
      type: preonly
      maximum iterations=10000, initial guess is zero
      tolerances: relative=1e-05, absolute=1e-50, divergence=10000.
      left preconditioning
      using NONE norm type for convergence test
    PC Object: (redistribute_fieldsplit_1_) 2 MPI processes
      type: bjacobi
        number of blocks = 2
        Local solver information for first block is in the following KSP and PC objects on rank 0:
        Use -redistribute_fieldsplit_1_ksp_view ::ascii_info_detail to display information for all blocks
        KSP Object: (redistribute_fieldsplit_1_sub_) 1 MPI process
          type: preonly
          maximum iterations=10000, initial guess is zero
          tolerances: relative=1e-05, absolute=1e-50, divergence=10000.
          left preconditioning
          using NONE norm type for convergence test
        PC Object: (redistribute_fieldsplit_1_sub_) 1 MPI process
          type: ilu
            out-of-place factorization
            0 levels of fill
            tolerance for zero pivot 2.22045e-14
            matrix ordering: natural
            factor fill ratio given 1., needed 1.
              Factored matrix follows:
                Mat Object: (redistribute_fieldsplit_1_sub_) 1 MPI process
                  type: seqaij
                  rows=1, cols=1
                  package used to perform factorization: petsc
                  total: nonzeros=1, allocated nonzeros=1
                    not using I-node routines
          linear system matrix = precond matrix:
          Mat Object: (redistribute_fieldsplit_1_sub_) 1 MPI process
            type: seqaij
            rows=1, cols=1
            total: nonzeros=1, allocated nonzeros=1
            total number of mallocs used during MatSetValues calls=0
              not using I-node routines
      linear system matrix = precond matrix:
      Mat Object: (redistribute_fieldsplit_1_) 2 MPI processes
        type: mpiaij
        rows=2, cols=2
        total: nonzeros=2, allocated nonzeros=2
        total number of mallocs used during MatSetValues calls=0
          not using I-node (on process 0) routines
    linear system matrix = precond matrix:
    Mat Object: 2 MPI processes
      type: mpiaij
      rows=3, cols=3
      total: nonzeros=5, allocated nonzeros=5
      total number of mallocs used during MatSetValues calls=0
        not using I-node (on process 0) routines
  linear system matrix = precond matrix:
  Mat Object: 2 MPI processes
    type: mpiaij
    rows=6, cols=6
    total: nonzeros=12, allocated nonzeros=12
    total number of mallocs used during MatSetValues calls=0
      not using I-node (on process 0) routines
  0 KSP Residual norm 2.449489742783e+00
    Residual norms for redistribute_ solve.
    0 KSP Residual norm 8.479468414379e-17
  1 KSP Residual norm 3.330669073875e-16
KSP Object: 2 MPI processes
  type: preonly
  maximum iterations=10000, nonzero initial guess
  tolerances: relative=1e-05, absolute=1e-50, divergence=10000.
  left preconditioning
  using NONE norm type for convergence test
PC Object: 2 MPI processes
  type: redistribute
      Number rows eliminated 3 Percentage rows eliminated 50.
    Redistribute preconditioner: 
  KSP Object: (redistribute_) 2 MPI processes
    type: gmres
      restart=30, using Classical (unmodified) Gram-Schmidt Orthogonalization with no iterative refinement
      happy breakdown tolerance 1e-30
    maximum iterations=10000, nonzero initial guess
    tolerances: relative=1e-05, absolute=1e-50, divergence=10000.
    left preconditioning
    using PRECONDITIONED norm type for convergence test
  PC Object: (redistribute_) 2 MPI processes
    type: fieldsplit
      FieldSplit with MULTIPLICATIVE composition: total splits = 2
      Solver info for each split is in the following KSP objects:
    Split number 0 Defined by IS
    KSP Object: (redistribute_fieldsplit_0_) 2 MPI processes
      type: preonly
      maximum iterations=10000, initial guess is zero
      tolerances: relative=1e-05, absolute=1e-50, divergence=10000.
      left preconditioning
      using NONE norm type for convergence test
    PC Object: (redistribute_fieldsplit_0_) 2 MPI processes
      type: bjacobi
        number of blocks = 2
        Local solver information for first block is in the following KSP and PC objects on rank 0:
        Use -redistribute_fieldsplit_0_ksp_view ::ascii_info_detail to display information for all blocks
        KSP Object: (redistribute_fieldsplit_0_sub_) 1 MPI process
          type: preonly
          maximum iterations=10000, initial guess is zero
          tolerances: relative=1e-05, absolute=1e-50, divergence=10000.
          left preconditioning
          using NONE norm type for convergence test
        PC Object: (redistribute_fieldsplit_0_sub_) 1 MPI process
          type: ilu
            out-of-place factorization
            0 levels of fill
            tolerance for zero pivot 2.22045e-14
            matrix ordering: natural
            factor fill ratio given 1., needed 1.
              Factored matrix follows:
                Mat Object: (redistribute_fieldsplit_0_sub_) 1 MPI process
                  type: seqaij
                  rows=1, cols=1
                  package used to perform factorization: petsc
                  total: nonzeros=1, allocated nonzeros=1
                    not using I-node routines
          linear system matrix = precond matrix:
          Mat Object: (redistribute_fieldsplit_0_sub_) 1 MPI process
            type: seqaij
            rows=1, cols=1
            total: nonzeros=1, allocated nonzeros=1
            total number of mallocs used during MatSetValues calls=0
              not using I-node routines
      linear system matrix = precond matrix:
      Mat Object: (redistribute_fieldsplit_0_) 2 MPI processes
        type: mpiaij
        rows=1, cols=1
        total: nonzeros=1, allocated nonzeros=1
        total number of mallocs used during MatSetValues calls=0
          not using I-node (on process 0) routines
    Split number 1 Defined by IS
    KSP Object: (redistribute_fieldsplit_1_) 2 MPI processes
      type: preonly
      maximum iterations=10000, initial guess is zero
      tolerances: relative=1e-05, absolute=1e-50, divergence=10000.
      left preconditioning
      using NONE norm type for convergence test
    PC Object: (redistribute_fieldsplit_1_) 2 MPI processes
      type: bjacobi
        number of blocks = 2
        Local solver information for first block is in the following KSP and PC objects on rank 0:
        Use -redistribute_fieldsplit_1_ksp_view ::ascii_info_detail to display information for all blocks
        KSP Object: (redistribute_fieldsplit_1_sub_) 1 MPI process
          type: preonly
          maximum iterations=10000, initial guess is zero
          tolerances: relative=1e-05, absolute=1e-50, divergence=10000.
          left preconditioning
          using NONE norm type for convergence test
        PC Object: (redistribute_fieldsplit_1_sub_) 1 MPI process
          type: ilu
            out-of-place factorization
            0 levels of fill
            tolerance for zero pivot 2.22045e-14
            matrix ordering: natural
            factor fill ratio given 1., needed 1.
              Factored matrix follows:
                Mat Object: (redistribute_fieldsplit_1_sub_) 1 MPI process
                  type: seqaij
                  rows=1, cols=1
                  package used to perform factorization: petsc
                  total: nonzeros=1, allocated nonzeros=1
                    not using I-node routines
          linear system matrix = precond matrix:
          Mat Object: (redistribute_fieldsplit_1_sub_) 1 MPI process
            type: seqaij
            rows=1, cols=1
            total: nonzeros=1, allocated nonzeros=1
            total number of mallocs used during MatSetValues calls=0
              not using I-node routines
      linear system matrix = precond matrix:
      Mat Object: (redistribute_fieldsplit_1_) 2 MPI processes
        type: mpiaij
        rows=2, cols=2
        total: nonzeros=2, allocated nonzeros=2
        total number of mallocs used during MatSetValues calls=0
          not using I-node (on process 0) routines
    linear system matrix = precond matrix:
    Mat Object: 2 MPI processes
      type: mpiaij
      rows=3, cols=3
      total: nonzeros=5, allocated nonzeros=5
      total number of mallocs used during MatSetValues calls=0
        not using I-node (on process 0) routines
  linear system matrix = precond matrix:
  Mat Object: 2 MPI processes
    type: mpiaij
    rows=6, cols=6
    total: nonzeros=12, allocated nonzeros=12
    total number of mallocs used during MatSetValues calls=0
      not using I-node (on process 0) routines
  0 KSP Residual norm 2.449489742783e+00
    Residual norms for redistribute_ solve.
    0 KSP Residual norm 8.529808416651e-02
    1 KSP Residual norm 1.682101381914e-03
    2 KSP Residual norm 2.122130848081e-17
  1 KSP Residual norm 2.482534153247e-16
